# 抽出方法: "pc" (主成分分析)
# 因子数: nfactors=4 (4因子を抽出)
# 回転方法: rotate="varimax" (直交回転のバリマックス)
fa_result <- fa(r = df,
nfactors = 4,
fm = "pc",
rotate = "varimax")
# 結果の表示
fa_result
# 詳細な結果の表示（負荷量のグラフ化）
# cut (負荷量の表示しきい値)
fa.diagram(fa_result, cut = 0.3)
fa.plot(fa_result)
fa.diagram()
# 因子負荷量のヒートマップ
# 必要なパッケージ
library(ggplot2)
library(reshape2)
install.packages(reshape2)
install.packages("reshape2")
library(reshape2)
# 因子負荷量を抽出（loadings を数値行列として取り出す）
loadings <- as.data.frame(unclass(fa_result$loadings))
# 因子（列）を指定（MR1〜MR4を使用）
loadings <- loadings[, 1:4]
# 項目名を列に追加
loadings$item <- rownames(loadings)
# long形式に変換（ggplot用）
df_plot <- melt(loadings, id = "item")
# ヒートマップ描画
ggplot(df_plot, aes(x = variable, y = item, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2(
low = "blue",
mid = "white",
high = "red",
midpoint = 0,
limits = c(-1, 1)
) +
theme_minimal(base_size = 14) +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
axis.title.x = element_blank(),
axis.title.y = element_blank()
) +
labs(
title = "因子負荷量ヒートマップ",
fill = "負荷量"
)
# 主成分法 (fm="pa" - Principal Axis Factor Analysisもよく使われます)
# 抽出方法: "pc" (主成分分析)
# 因子数: nfactors=4 (4因子を抽出)
# 回転方法: rotate="varimax" (直交回転のバリマックス)
fa_result <- fa(r = df,
nfactors = 4,
fm = "pa",
rotate = "varimax")
# 結果の表示
fa_result
# 詳細な結果の表示（負荷量のグラフ化）
# cut (負荷量の表示しきい値)
fa.diagram(fa_result, cut = 0.3)
# 因子得点
factor_scores <- fa_result$scores
# 因子負荷量を抽出（loadings を数値行列として取り出す）
loadings <- as.data.frame(unclass(fa_result$loadings))
# 因子（列）を指定（MR1〜MR4を使用）
loadings <- loadings[, 1:4]
# 項目名を列に追加
loadings$item <- rownames(loadings)
# long形式に変換（ggplot用）
df_plot <- melt(loadings, id = "item")
# ヒートマップ描画
ggplot(df_plot, aes(x = variable, y = item, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2(
low = "blue",
mid = "white",
high = "red",
midpoint = 0,
limits = c(-1, 1)
) +
theme_minimal(base_size = 14) +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
axis.title.x = element_blank(),
axis.title.y = element_blank()
) +
labs(
title = "因子負荷量ヒートマップ",
fill = "負荷量"
)
# 固有値の確認（これで因子の数を決める？）
eigen_values <- eigen(cor(df))$values
eigen_values
# --- 最適なクラスター数の決定（エルボー法） ---
# Kの数に応じたWSS (Within-Cluster Sum of Squares)を格納するベクトル
wss <- numeric(15)
# K=1からK=15までK-meansを実行し、WSSを計算
for (k in 1:15) {
# nstart=25 は、初期値のランダムな選び方による影響を減らすため、25回繰り返す設定
kmeans_result <- kmeans(factor_scores, centers = k, nstart = 25)
wss[k] <- kmeans_result$tot.withinss
}
# エルボー法のプロット
plot(1:15, wss, type = "b",
xlab = "Number of Clusters (K)",
ylab = "Within-Cluster Sum of Squares (WSS)",
main = "Elbow Method for Optimal K")
# K=3でK-meansを実行 (最適なKはエルボー法の結果に基づいて変更してください)
final_k <- 4
set.seed(123) # 結果の再現性を確保するためにシードを設定
kmeans_final <- kmeans(factor_scores, centers = final_k, nstart = 25)
# --- 結果の統合 ---
# 1. 因子得点データにクラスターの割り当てを追加
factor_scores_with_cluster <- data.frame(factor_scores,
Cluster = kmeans_final$cluster)
# 2. 各クラスターの中心（特徴）を抽出
# これが各クラスターのプロファイルを表します
cluster_centers <- kmeans_final$centers
print(cluster_centers)
print(kmeans_final$size)
cluster_assignment <- kmeans_final$cluster
cluster_assignment <- kmeans_final$cluster
payment_vector <- exceldata_2[, 19]
# 3. 2つのベクトルを新しいデータフレームとして結合
# 行数（77）が一致していれば、この方法は最も確実です。
combined_data_final <- data.frame(
Cluster = cluster_assignment,
Payment_Flag = payment_vector
)
utilization_rate <- aggregate(
x = combined_data_final$Made_InApp_Purchase,  # 課金フラグのベクトル
by = list(Cluster = combined_data_final$Cluster), # クラスター番号のベクトルでグループ化
FUN = mean # 平均（＝課金率）を計算
)
print(utilization_rate)
# combined_data_final の Play_Time_Category 列を使ってクロス集計と検定を実行
exceldata_2 <- cbind(exceldata_2, cluster_assignment)
# 1. クロス集計表（分割表）の作成
# 行: クラスター (4水準), 列: プレイ時間カテゴリ (N水準)
contingency_table_time <- table(exceldata_2$cluster_assignment,
exceldata_2$Avg_Hours_SP_Weekend)
print(contingency_table_time)
# カイ二乗検定的にはだめそうだけど、実数値は傾向ありそうだから使っちゃう
# 2. カイ二乗検定の実行
chi_sq_test_time <- chisq.test(contingency_table_time)
print("--- カイ二乗検定の結果 ---")
print(chi_sq_test_time)
# 課金者数と非課金者数のテーブルを作る
tbl <- matrix(
c(5,11,
11,6,
8,12,
13,16),
nrow = 4,
byrow = TRUE
)
# カイ二乗検定
chisq.test(tbl)
# 課金者数と非課金者数のテーブルを作る
tbl <- matrix(
c(5,11,
11,6,
8,12,
13,16),
nrow = 4,
byrow = TRUE
)
# カイ二乗検定
chisq.test(tbl)
# K=3でK-meansを実行 (最適なKはエルボー法の結果に基づいて変更してください)
final_k <- 3
set.seed(123) # 結果の再現性を確保するためにシードを設定
kmeans_final <- kmeans(factor_scores, centers = final_k, nstart = 25)
# --- 結果の統合 ---
# 1. 因子得点データにクラスターの割り当てを追加
factor_scores_with_cluster <- data.frame(factor_scores,
Cluster = kmeans_final$cluster)
# 2. 各クラスターの中心（特徴）を抽出
# これが各クラスターのプロファイルを表します
cluster_centers <- kmeans_final$centers
print(cluster_centers)
print(kmeans_final$size)
cluster_assignment <- kmeans_final$cluster
payment_vector <- exceldata_2[, 19]
# 3. 2つのベクトルを新しいデータフレームとして結合
# 行数（77）が一致していれば、この方法は最も確実です。
combined_data_final <- data.frame(
Cluster = cluster_assignment,
Payment_Flag = payment_vector
)
utilization_rate <- aggregate(
x = combined_data_final$Made_InApp_Purchase,  # 課金フラグのベクトル
by = list(Cluster = combined_data_final$Cluster), # クラスター番号のベクトルでグループ化
FUN = mean # 平均（＝課金率）を計算
)
cluster_assignment <- kmeans_final$cluster
payment_vector <- exceldata_2[, 19]
# 3. 2つのベクトルを新しいデータフレームとして結合
# 行数（77）が一致していれば、この方法は最も確実です。
combined_data_final <- data.frame(
Cluster = cluster_assignment,
Payment_Flag = payment_vector
)
utilization_rate <- aggregate(
x = combined_data_final$Made_InApp_Purchase,  # 課金フラグのベクトル
by = list(Cluster = combined_data_final$Cluster), # クラスター番号のベクトルでグループ化
FUN = mean # 平均（＝課金率）を計算
)
print(utilization_rate)
# K=3でK-meansを実行 (最適なKはエルボー法の結果に基づいて変更してください)
final_k <- 3
set.seed(123) # 結果の再現性を確保するためにシードを設定
kmeans_final <- kmeans(factor_scores, centers = final_k, nstart = 25)
# --- 結果の統合 ---
# 1. 因子得点データにクラスターの割り当てを追加
factor_scores_with_cluster <- data.frame(factor_scores,
Cluster = kmeans_final$cluster)
# 2. 各クラスターの中心（特徴）を抽出
# これが各クラスターのプロファイルを表します
cluster_centers <- kmeans_final$centers
print(cluster_centers)
print(kmeans_final$size)
cluster_assignment <- kmeans_final$cluster
payment_vector <- exceldata_2[, 19]
# 3. 2つのベクトルを新しいデータフレームとして結合
# 行数（77）が一致していれば、この方法は最も確実です。
combined_data_final <- data.frame(
Cluster = cluster_assignment,
Payment_Flag = payment_vector
)
combined_data_final$Payment_Flag
utilization_rate <- aggregate(
x = combined_data_final$Payment_Flag,  # 課金フラグのベクトル
by = list(Cluster = combined_data_final$Cluster), # クラスター番号のベクトルでグループ化
FUN = mean # 平均（＝課金率）を計算
)
print(utilization_rate)
# 1. クロス集計表（分割表）の作成
# 行: クラスター (4水準), 列: プレイ時間カテゴリ (N水準)
contingency_table_time <- table(exceldata_2$cluster_assignment,
exceldata_2$Avg_Hours_SP_Weekend)
print(contingency_table_time)
# combined_data_final の Play_Time_Category 列を使ってクロス集計と検定を実行
exceldata_2 <- cbind(exceldata_2, cluster_assignment)
# 1. クロス集計表（分割表）の作成
# 行: クラスター (4水準), 列: プレイ時間カテゴリ (N水準)
contingency_table_time <- table(exceldata_2$cluster_assignment,
exceldata_2$Avg_Hours_SP_Weekend)
print(contingency_table_time)
print(utilization_rate)
cluster_assignment <- kmeans_final$cluster
# combined_data_final の Play_Time_Category 列を使ってクロス集計と検定を実行
exceldata_2 <- cbind(exceldata_2, cluster_assignment)
# 1. クロス集計表（分割表）の作成
# 行: クラスター (4水準), 列: プレイ時間カテゴリ (N水準)
contingency_table_time <- table(exceldata_2$cluster_assignment,
exceldata_2$Avg_Hours_SP_Weekend)
print(contingency_table_time)
View(exceldata_2)
# combined_data_final の Play_Time_Category 列を使ってクロス集計と検定を実行
exceldata_2$cluster_assignment <- kmeans_final$cluster
# 1. クロス集計表（分割表）の作成
# 行: クラスター (4水準), 列: プレイ時間カテゴリ (N水準)
contingency_table_time <- table(exceldata_2$cluster_assignment,
exceldata_2$Avg_Hours_SP_Weekend)
print(contingency_table_time)
# クラスターのプロット
library(plotly)
fig <- plot_ly(factor_scores_with_cluster,
x = ~PA1, y = ~PA2, z = ~PA3,
color = ~factor(Cluster),          # クラスターで色分け
colors = c("red","blue","green"),  # 色を3クラスタに対応
type = "scatter3d", mode = "markers",
marker = list(size = 5))           # マーカーは全部同じ
fig <- fig %>% layout(scene = list(xaxis = list(title = 'PA1'),
yaxis = list(title = 'PA2'),
zaxis = list(title = 'PA3')),
legend = list(title = list(text='Cluster')))
fig
df <- exceldata_2[24:37] # ここ変わってるはずだから変更する
# 因子分析もやってみる
# パッケージの読み込み
# install.packages("psych")
library(psych)
eigen_values
# 固有値の確認（これで因子の数を決める？）
eigen_values <- eigen(cor(df))$values
eigen_values
# 抽出方法: "pa" (主成分分析)
# 因子数: nfactors=4 (4因子を抽出)
# 回転方法: rotate="varimax" (直交回転のバリマックス)
fa_result <- fa(r = df,
nfactors = 4,
fm = "pa",
rotate = "varimax")
# 結果の表示
fa_result
# 因子得点
factor_scores <- fa_result$scores
# K=3でK-meansを実行 (最適なKはエルボー法の結果に基づいて変更してください)
final_k <- 3
kmeans_final <- kmeans(factor_scores, centers = final_k, nstart = 25)
# --- 結果の統合 ---
# 1. 因子得点データにクラスターの割り当てを追加
factor_scores_with_cluster <- data.frame(factor_scores,
Cluster = kmeans_final$cluster)
# 2. 各クラスターの中心（特徴）を抽出
# これが各クラスターのプロファイルを表します
cluster_centers <- kmeans_final$centers
print(cluster_centers)
print(kmeans_final$size)
# K=3でK-meansを実行 (最適なKはエルボー法の結果に基づいて変更してください)
final_k <- 3
set.seed(123) # 結果の再現性を確保するためにシードを設定
kmeans_final <- kmeans(factor_scores, centers = final_k, nstart = 25)
# --- 結果の統合 ---
# 1. 因子得点データにクラスターの割り当てを追加
factor_scores_with_cluster <- data.frame(factor_scores,
Cluster = kmeans_final$cluster)
utilization_rate <- aggregate(
x = combined_data_final$Payment_Flag,  # 課金フラグのベクトル
by = list(Cluster = combined_data_final$Cluster), # クラスター番号のベクトルでグループ化
FUN = mean # 平均（＝課金率）を計算
)
print(utilization_rate)
cluster_assignment <- kmeans_final$cluster
payment_vector <- exceldata_2[, 19]
# 3. 2つのベクトルを新しいデータフレームとして結合
# 行数（77）が一致していれば、この方法は最も確実です。
combined_data_final <- data.frame(
Cluster = cluster_assignment,
Payment_Flag = payment_vector
)
utilization_rate <- aggregate(
x = combined_data_final$Payment_Flag,  # 課金フラグのベクトル
by = list(Cluster = combined_data_final$Cluster), # クラスター番号のベクトルでグループ化
FUN = mean # 平均（＝課金率）を計算
)
# combined_data_final の Play_Time_Category 列を使ってクロス集計と検定を実行
exceldata_2$cluster_assignment <- kmeans_final$cluster
print(utilization_rate)
library(readxl)
exceldata_2 <- read_excel("data/data_3.xlsx")
View(exceldata_2)
df <- exceldata_2[24:37] # ここ変わってるはずだから変更する
View(df)
# 因子分析もやってみる
# パッケージの読み込み
# install.packages("psych")
library(psych)
# 固有値の確認（これで因子の数を決める？）
eigen_values <- eigen(cor(df))$values
eigen_values
# 抽出方法: "pa" (主成分分析)
# 因子数: nfactors=4 (4因子を抽出)
# 回転方法: rotate="varimax" (直交回転のバリマックス)
fa_result <- fa(r = df,
nfactors = 4,
fm = "pa",
rotate = "varimax")
# 結果の表示
fa_result
# 因子得点
factor_scores <- fa_result$scores
# 因子負荷量のヒートマップ
# 必要なパッケージ
library(ggplot2)
library(reshape2)
# 因子負荷量を抽出（loadings を数値行列として取り出す）
loadings <- as.data.frame(unclass(fa_result$loadings))
# 因子（列）を指定（MR1〜MR4を使用）
loadings <- loadings[, 1:4]
# 項目名を列に追加
loadings$item <- rownames(loadings)
# long形式に変換（ggplot用）
df_plot <- melt(loadings, id = "item")
# K=3でK-meansを実行 (最適なKはエルボー法の結果に基づいて変更してください)
final_k <- 3
kmeans_final <- kmeans(factor_scores, centers = final_k, nstart = 25)
# --- 結果の統合 ---
# 1. 因子得点データにクラスターの割り当てを追加
factor_scores_with_cluster <- data.frame(factor_scores,
Cluster = kmeans_final$cluster)
# 2. 各クラスターの中心（特徴）を抽出
# これが各クラスターのプロファイルを表します
cluster_centers <- kmeans_final$centers
print(cluster_centers)
print(kmeans_final$size)
cluster_assignment <- kmeans_final$cluster
payment_vector <- exceldata_2[, 19]
View(payment_vector)
# 3. 2つのベクトルを新しいデータフレームとして結合
# 行数（77）が一致していれば、この方法は最も確実です。
combined_data_final <- data.frame(
Cluster = cluster_assignment,
Payment_Flag = payment_vector
)
utilization_rate <- aggregate(
x = combined_data_final$Payment_Flag,  # 課金フラグのベクトル
by = list(Cluster = combined_data_final$Cluster), # クラスター番号のベクトルでグループ化
FUN = mean # 平均（＝課金率）を計算
)
# 3. 2つのベクトルを新しいデータフレームとして結合
# 行数（77）が一致していれば、この方法は最も確実です。
combined_data_final <- data.frame(
Cluster = cluster_assignment,
Payment_Flag = payment_vector
)
utilization_rate <- aggregate(
x = combined_data_final$Payment_Flag,  # 課金フラグのベクトル
by = list(Cluster = combined_data_final$Cluster), # クラスター番号のベクトルでグループ化
FUN = mean # 平均（＝課金率）を計算
)
View(combined_data_final)
# 3. 2つのベクトルを新しいデータフレームとして結合
# 行数（77）が一致していれば、この方法は最も確実です。
combined_data_final <- data.frame(
Cluster = cluster_assignment,
Payment_Flag = payment_vector
)
utilization_rate <- aggregate(
x = combined_data_final$payment_vector,  # 課金フラグのベクトル
by = list(Cluster = combined_data_final$Cluster), # クラスター番号のベクトルでグループ化
FUN = mean # 平均（＝課金率）を計算
)
utilization_rate <- aggregate(
x = combined_data_final$payment_vector,  # 課金フラグのベクトル
by = list(Cluster = combined_data_final$Cluster), # クラスター番号のベクトルでグループ化
FUN = mean # 平均（＝課金率）を計算
)
utilization_rate <- aggregate(
x = combined_data_final$Made_InApp_Purchase,  # 課金フラグのベクトル
by = list(Cluster = combined_data_final$Cluster), # クラスター番号のベクトルでグループ化
FUN = mean # 平均（＝課金率）を計算
)
utilization_rate <- aggregate(
x = combined_data_final$Made_InApp_Purchase,  # 課金フラグのベクトル
by = list(Cluster = combined_data_final$Cluster), # クラスター番号のベクトルでグループ化
FUN = mean # 平均（＝課金率）を計算
)
print(utilization_rate)
View(combined_data_final)
View(combined_data_final)
ls
# データの読み込み
library(readxl)
data_1 <- read_excel("data/data_3.xlsx")
View(data_1)
View(data_1)
# スマホ利用用途の変数名リスト（Rでの列名として使用）
activity_cols <- c("Game_SP", "SNS_Chat", "SNS_View",
"SNS_Post", "Watch_Media", "Reading",
"Study_SP", "Research", "Shop_SP")
library(readxl)
exceldata_170_1119 <- read_excel("data/exceldata_170_1119.xlsx")
View(exceldata_170_1119)
# df <- read_excel("data/exceldata_158_1109.xlsx", sheet = "sheet1_1_全員回答")
df <- read_excel("data/exceldata_170_1119.xlsx")
View(df)
# df <- read_excel("data/exceldata_158_1109.xlsx", sheet = "sheet1_1_全員回答")
df <- read_excel("data/exceldata_170_1119.xlsx", sheet = "sheet1_1")
library(readxl)
# df <- read_excel("data/exceldata_158_1109.xlsx", sheet = "sheet1_1_全員回答")
df <- read_excel("data/exceldata_170_1119.xlsx", sheet = "sheet1_1")
# df <- read_excel("data/exceldata_158_1109.xlsx", sheet = "sheet1_1_全員回答")
df <- read_excel("data/exceldata_170_1119.xlsx", sheet = "sheet1")
# df <- read_excel("data/exceldata_158_1109.xlsx", sheet = "sheet1_1_全員回答")
df <- read_excel("data/exceldata_170_1119.xlsx", sheet = "Sheet1")
View(df)
# dplyrパッケージをロード
library(dplyr)
#「SNSを見る」から「その他アウトドアの趣味」までの全ての列に対して「- 1」の操作を適用
df <- df %>%
mutate(
across(
# 列の範囲を「開始列名:終了列名」で指定
Game_SP:Hobby_Outdoor,
# 適用する関数を指定 (現在の列の値から1を引く)
~ .x - 1
)
)
# パッケージのインストール (初回のみ)
# install.packages("writexl")
# 出力
library(writexl)
write_xlsx(df, "data/data_4.xlsx")
data_1 <- read_excel("data/data_4.xlsx")
# スマホ利用用途の変数名リスト（Rでの列名として使用）
activity_cols <- c("Game_SP", "SNS_Chat", "SNS_View",
"SNS_Post", "Watch_Media", "Reading",
"Study_SP", "Research", "Shop_SP")
# 目的変数（スマホゲーム: 0/1）の変数名
target_col <- "Play_SP_Game"
target_col2 <- "Play_Console"
# 主成分分析に使用するデータフレーム (説明変数X)
X <- data_1[, activity_cols]
# 目的変数Y
Y <- data_1[[target_col]]
# 目的変数Y2(コンシューマーゲーム)
Y2 <- data_1[[target_col2]]
# 主成分分析に使用するデータフレーム (説明変数X)
X <- data_1[, activity_cols]
# 目的変数Y
Y <- data_1[[target_col]]
# -----------------
# 主成分分析 (PCA) の実行
# -----------------
# データを標準化（scale = TRUE）してからPCAを実行
pca_result <- prcomp(X, scale = TRUE)
summary(pca_result)
